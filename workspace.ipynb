{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57111373",
   "metadata": {},
   "source": [
    "## Drone Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essential imports\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# plotting and display\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# import YOLO model from ultralytics package\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# custom utilities\n",
    "from utils import * #set_device\n",
    "\n",
    "# reflect changes in src code immediately without restarting kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159cd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device depending on available GPU\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained YOLOv8 model\n",
    "model = YOLO(\"yolov8m.pt\")  # n for nano, s for small, m for medium, l for large, x for extra large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7a418",
   "metadata": {},
   "source": [
    "#### Try on drone video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aee16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all datasets path\n",
    "data_path = './data/drone-tracking-datasets/'\n",
    "\n",
    "# select dataset and camera\n",
    "dataset_num = 3\n",
    "cam_num = 0\n",
    "video_path = os.path.join(data_path, f'dataset{dataset_num}/cam{cam_num}.mp4')\n",
    "\n",
    "# get sample frame and store width and height\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, sample_frame = cap.read()\n",
    "cap.release()\n",
    "sample_frame_rgb = cv2.cvtColor(sample_frame, cv2.COLOR_BGR2RGB)\n",
    "frame_height, frame_width, _ = sample_frame.shape\n",
    "print(f\"Frame size: {frame_width} x {frame_height}\")\n",
    "plt.imshow(sample_frame_rgb)\n",
    "\n",
    "# select tracker\n",
    "tracker = \"sort.yaml\"  # or 'bytetrack.yaml', 'strongsort.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9cd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run detection on video\n",
    "results = model.predict(\n",
    "    source=video_path, \n",
    "    device=device,   # set the device\n",
    "    tracker=tracker,\n",
    "    show=True, # display live output in external window (do not return generator)\n",
    "    save=True,  # save output video with bounding boxes to runs/detect/\n",
    "    #stream=True  # return a generator that yields results for each frame, doesn't store whole video in memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4200d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tracking\n",
    "\n",
    "# save trajectory to CSV\n",
    "csv_file = \"trajectory_1.csv\"\n",
    "\n",
    "trajectory = []  # list to store (frame_id, x_center, y_center)\n",
    "\n",
    "for frame_id, result in enumerate(results, start=1):\n",
    "    if len(result.boxes) > 0:\n",
    "        # Take first detection (assuming single drone)\n",
    "        box = result.boxes[0].xywh[0]  # [x_center, y_center, width, height] in pixels\n",
    "        x_center, y_center = box[0].item(), box[1].item()\n",
    "    else:\n",
    "        # If no detection, log NaN or skip\n",
    "        x_center, y_center = float('nan'), float('nan')\n",
    "\n",
    "    trajectory.append([frame_id, x_center, y_center])\n",
    "\n",
    "# save to CSV\n",
    "with open(csv_file, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"frame_id\", \"x_center\", \"y_center\"])\n",
    "    writer.writerows(trajectory)\n",
    "\n",
    "print(f\"Trajectory saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f65321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract x, y values in pixels, skipping NaNs\n",
    "x_vals = np.array([x for _, x, y in trajectory])\n",
    "y_vals = np.array([y for _, x, y in trajectory])\n",
    "\n",
    "# Threshold in pixels\n",
    "distance_threshold = 50\n",
    "\n",
    "# Prepare lists of segments\n",
    "segments_x = []\n",
    "segments_y = []\n",
    "\n",
    "current_seg_x = []\n",
    "current_seg_y = []\n",
    "\n",
    "for i in range(len(x_vals)):\n",
    "    x, y = x_vals[i], y_vals[i]\n",
    "    \n",
    "    if np.isnan(x) or np.isnan(y):\n",
    "        # Missing detection → start new segment\n",
    "        if current_seg_x:\n",
    "            segments_x.append(current_seg_x)\n",
    "            segments_y.append(current_seg_y)\n",
    "            current_seg_x, current_seg_y = [], []\n",
    "        continue\n",
    "    \n",
    "    if current_seg_x:\n",
    "        # Compute distance to previous point\n",
    "        dx = x - current_seg_x[-1]\n",
    "        dy = y - current_seg_y[-1]\n",
    "        dist = np.sqrt(dx**2 + dy**2)\n",
    "        if dist > distance_threshold:\n",
    "            # Jump too far → start new segment\n",
    "            segments_x.append(current_seg_x)\n",
    "            segments_y.append(current_seg_y)\n",
    "            current_seg_x, current_seg_y = [], []\n",
    "\n",
    "    # Add point to current segment\n",
    "    current_seg_x.append(x)\n",
    "    current_seg_y.append(y)\n",
    "\n",
    "# Add last segment\n",
    "if current_seg_x:\n",
    "    segments_x.append(current_seg_x)\n",
    "    segments_y.append(current_seg_y)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(sample_frame_rgb)\n",
    "for seg_x, seg_y in zip(segments_x, segments_y):\n",
    "    plt.plot(seg_x, seg_y, marker='o', color='red', linewidth=2, markersize=1)\n",
    "\n",
    "#plt.title(\"Drone Trajectory Over Sample Frame (with breaks)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7393e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and Y lists with NaNs for missing detections\n",
    "x_vals = np.array([x if not np.isnan(x) else np.nan for _, x, y in trajectory])\n",
    "y_vals = np.array([y if not np.isnan(y) else np.nan for _, x, y in trajectory])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(sample_frame_rgb)\n",
    "\n",
    "# Plot segments separately to break lines at NaNs\n",
    "# Using np.ma (masked arrays) to ignore NaNs in line segments\n",
    "plt.plot(np.ma.masked_invalid(x_vals), np.ma.masked_invalid(y_vals),\n",
    "         marker='o', color='red', linewidth=2, markersize=2)\n",
    "\n",
    "plt.title(\"Drone Trajectory Over Sample Frame\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out frames where drone was not detected\n",
    "x_vals = [x for _, x, y in trajectory if not (x != x)]  # ignore NaNs\n",
    "y_vals = [y for _, x, y in trajectory if not (y != y)]\n",
    "\n",
    "# plot trajectory over sample frame\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(sample_frame_rgb)\n",
    "plt.plot(x_vals, y_vals, marker='o', color='red', linewidth=2, markersize=4)\n",
    "plt.title(\"Drone Trajectory Over Sample Frame\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counters\n",
    "detected_count = 0\n",
    "missed_count = 0\n",
    "\n",
    "for result in results:\n",
    "    if len(result.boxes) > 0:  # any detections in this frame?\n",
    "        detected_count += 1\n",
    "    else:\n",
    "        missed_count += 1\n",
    "\n",
    "print(f\"Detected in {detected_count} frames\")\n",
    "print(f\"Missed in {missed_count} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c617e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the detections in camera 0 in the first dataset\n",
    "# there are 5334 frames total\n",
    "# of these there are 2416 frames that have no detections\n",
    "# so there are 2918 frames with detections\n",
    "# 55% detection rate\n",
    "\n",
    "# for the nano model\n",
    "# Detected in 1606 frames\n",
    "# Missed in 3728 frames\n",
    "# 30% detection rate\n",
    "\n",
    "# for the small model\n",
    "# Detected in 2357 frames\n",
    "# Missed in 2977 frames\n",
    "# 44% detection rate, much better!\n",
    "\n",
    "# for the medium model\n",
    "# Detected in 2704 frames\n",
    "# Missed in 2630 frames\n",
    "# 50.7% detection rate, even better!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_zero = 0\n",
    "total_frames = 0\n",
    "file_name = os.path.join(data_path, 'dataset1/detections/cam0.txt')  \n",
    "\n",
    "# Replace 'data.txt' with your file path\n",
    "with open(file_name, \"r\") as f:\n",
    "    for line in f:\n",
    "        total_frames += 1\n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        \n",
    "        # Split line into columns\n",
    "        cols = line.strip().split()\n",
    "        \n",
    "        # Convert 2nd and 3rd columns to float\n",
    "        col2, col3 = float(cols[1]), float(cols[2])\n",
    "        \n",
    "        # Check if both are 0\n",
    "        if col2 == 0.0 and col3 == 0.0:\n",
    "            count_zero += 1\n",
    "\n",
    "print(f\"Number of rows where 2nd and 3rd columns are 0: {count_zero}\")\n",
    "print(f\"Total number of frames: {total_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results frame by frame inline, by iterating through the generator\n",
    "# otherwise can open in external window with show=True above\n",
    "\n",
    "for result in results:\n",
    "    annotated_frame = result.plot()\n",
    "    annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.imshow(annotated_frame)\n",
    "    plt.axis(\"off\")\n",
    "    clear_output(wait=True)  # clear previous cell output\n",
    "    display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab first frame only\n",
    "first_result = next(iter(results))\n",
    "\n",
    "# Plot with bounding boxes\n",
    "annotated_frame = first_result.plot()  # numpy array, BGR format\n",
    "annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Show with matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(annotated_frame)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"First Frame with YOLO Detections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put training code into YOLO format\n",
    "\n",
    "# <class_id> <x_center_norm> <y_center_norm> <width_norm> <height_norm>\n",
    "\n",
    "# need to decide bbox size or compute as we go from the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "bbox_width = 20   # in pixels\n",
    "bbox_height = 20  # in pixels\n",
    "image_width = 1280  # replace with actual image width\n",
    "image_height = 720  # replace with actual image height\n",
    "class_id = 0\n",
    "\n",
    "input_folder = \"detections\"  # folder with txt files\n",
    "output_folder = \"labels\"     # YOLO format labels\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if not file_name.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(input_folder, file_name), \"r\") as f_in, \\\n",
    "         open(os.path.join(output_folder, file_name), \"w\") as f_out:\n",
    "\n",
    "        for line in f_in:\n",
    "            frame_id, x, y = line.strip().split()\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "\n",
    "            # Normalize\n",
    "            x_norm = x / image_width\n",
    "            y_norm = y / image_height\n",
    "            w_norm = bbox_width / image_width\n",
    "            h_norm = bbox_height / image_height\n",
    "\n",
    "            f_out.write(f\"{class_id} {x_norm:.6f} {y_norm:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f718642",
   "metadata": {},
   "source": [
    "#### Plot the trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text file\n",
    "data_path = './data/drone-tracking-datasets/'\n",
    "trajectory_path = os.path.join(data_path, 'dataset3/trajectory/rtk.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory_static(trajectory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory_static_colored(trajectory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c63775",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory_interactive(trajectory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00609f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load trajectory\n",
    "#trajectory = np.loadtxt(\"trajectory.txt\")\n",
    "x, y, z = trajectory[:,0], trajectory[:,1], trajectory[:,2]\n",
    "\n",
    "# Create color scale based on time\n",
    "t = np.linspace(0, 1, len(x))\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x, y=y, z=z,\n",
    "    mode='markers+lines',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=t,\n",
    "        colorscale='Viridis',\n",
    "        showscale=True\n",
    "    ),\n",
    "    line=dict(\n",
    "        color='gray',\n",
    "        width=2\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z'\n",
    "    ),\n",
    "    title=\"Interactive 3D Drone Trajectory\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c8a04",
   "metadata": {},
   "source": [
    "#### Triangulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first i need to pick a reference camera for synchronization\n",
    "# then i can align the frames from other cameras (maybe start with one)\n",
    "\n",
    "# then when i have aligned frames that detect the xy coords of the drone at the same time\n",
    "# i can triangulate the 3d position\n",
    "# use the intrinsics (K and distortion params), and known camera positions to do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d62179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the detection on all videos and save to file\n",
    "data_path = './data/drone-tracking-datasets/'\n",
    "dataset_num = 3\n",
    "num_cams = 6\n",
    "\n",
    "# select tracker\n",
    "tracker = \"sort.yaml\"  # or 'bytetrack.yaml', 'strongsort.yaml'\n",
    "\n",
    "for cam_num in range(num_cams):\n",
    "    video_path = os.path.join(data_path, f'dataset{dataset_num}/cam{cam_num}.mp4')\n",
    "    csv_file = os.path.join('dataset3_result_detections', f'detections_cam{cam_num}.txt')\n",
    "\n",
    "    results = model.predict(source=video_path, tracker=tracker, save=False, stream=True)\n",
    "\n",
    "    trajectory = []  # list to store (frame_id, x_center, y_center)\n",
    "\n",
    "    for frame_id, result in enumerate(results, start=1):\n",
    "        if len(result.boxes) > 0:\n",
    "            # Take first detection (assuming single drone)\n",
    "            box = result.boxes[0].xywh[0]  # [x_center, y_center, width, height] in pixels\n",
    "            x_center, y_center = box[0].item(), box[1].item()\n",
    "        else:\n",
    "            # If no detection, log 0\n",
    "            x_center, y_center = 0.0, 0.0\n",
    "\n",
    "        trajectory.append([frame_id, x_center, y_center])\n",
    "\n",
    "    # save to CSV\n",
    "    with open(csv_file, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"frame_id\", \"x_center\", \"y_center\"])\n",
    "        writer.writerows(trajectory)\n",
    "\n",
    "    print(f\"Trajectory saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If CSV has header\n",
    "data = np.genfromtxt(\"trajectory.csv\", delimiter=\",\", skip_header=1)\n",
    "\n",
    "print(len(data))\n",
    "print(data[35,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ff81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info for dataset 3 and cams\n",
    "\n",
    "'''\n",
    "cam0 - gopro3\n",
    "cam1 - mate7\n",
    "cam2 - mate10\n",
    "cam3 - sony5n_1440x1080\n",
    "cam4 - sony5100\n",
    "cam5 - sonyG\n",
    "'''\n",
    "\n",
    "# locations\n",
    "'''\n",
    "44.535 11.56253333 -1.1467\n",
    "4.3962 -54.27346667 4.0965\n",
    "-42.5242 -21.00086667 -1.7639\n",
    "40.1912 44.79053333 -0.9379\n",
    "-34.8458 -44.00906667 1.4179\n",
    "-11.7524 62.93033333 -1.6659\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c500ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sync params for time shift and scale\n",
    "\n",
    "# Time scale (alpha) matrix\n",
    "alpha = np.array([\n",
    "    [1.0000, 0.5005, 0.4960, 0.4171, 0.5000, 0.8341],\n",
    "    [1.9982, 1.0000, 0.9910, 0.8333, 0.9990, 1.6667],\n",
    "    [2.0163, 1.0091, 1.0000, 0.8409, 1.0081, 1.6819],\n",
    "    [2.3978, 1.2000, 1.1892, 1.0000, 1.1988, 2.0000],\n",
    "    [2.0001, 1.0010, 0.9919, 0.8342, 1.0000, 1.6683],\n",
    "    [1.1989, 0.6000, 0.5946, 0.5000, 0.5994, 1.0000],\n",
    "])\n",
    "\n",
    "# Time shift (beta) matrix\n",
    "beta = np.array([\n",
    "    [0.00,     1013.95,  546.98,  251.16,  961.02,  137.51],\n",
    "    [-2026.04,    0.00, -457.83, -593.82,  -51.96, -1552.47],\n",
    "    [-1102.90,  461.99,    0.00, -208.81,  409.59,  -782.45],\n",
    "    [ -602.21,  712.57,  248.32,    0.00,  659.93,  -364.81],\n",
    "    [-1922.12,   52.01, -406.29, -551.00,    0.00, -1465.78],\n",
    "    [ -164.85,  931.45,  465.22,  182.40,  878.60,     0.00],\n",
    "])\n",
    "\n",
    "# decide ref cam\n",
    "ref_cam_num = 0\n",
    "\n",
    "# isolate relevant rows for both matrics\n",
    "alpha_ref = alpha[ref_cam_num, :]\n",
    "beta_ref = beta[ref_cam_num, :]\n",
    "\n",
    "print(alpha_ref)\n",
    "print(beta_ref) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the intrinsics for the cameras from json files\n",
    "\n",
    "camera = 'gopro3'\n",
    "json_file = os.path.join(data_path, f'calibration/{camera}/{camera}.json')\n",
    "\n",
    "# Load JSON\n",
    "with open(json_file, \"r\") as f:\n",
    "    cam_info = json.load(f)\n",
    "\n",
    "# Access attributes\n",
    "K = cam_info[\"K-matrix\"]\n",
    "dist = cam_info[\"distCoeff\"]\n",
    "fps = cam_info[\"fps\"]\n",
    "res = cam_info[\"resolution\"]\n",
    "\n",
    "print(\"K matrix:\", K)\n",
    "print(\"Distortion coeffs:\", dist)\n",
    "print(\"FPS:\", fps)\n",
    "print(\"Resolution:\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If CSV has header\n",
    "data_1 = np.genfromtxt(\"trajectory.csv\", delimiter=\",\", skip_header=1)\n",
    "data_2 = np.genfromtxt(\"trajectory_1.csv\", delimiter=\",\", skip_header=1)\n",
    "\n",
    "# chose second camera\n",
    "cam_num_2 = 1\n",
    "# get sync params\n",
    "alpha_2 = alpha_ref[cam_num_2]\n",
    "beta_2 = beta_ref[cam_num_2]\n",
    "\n",
    "\n",
    "# iterate through frames of reference camera\n",
    "for frame_id in range(len(data)):\n",
    "\n",
    "    # use sync info to get corresponding frame id from other camera\n",
    "    j = alpha_2 * frame_id + beta_2\n",
    "    if j < 0 or j >= len(data_2):\n",
    "        continue  # skip if out of bounds\n",
    "\n",
    "    # get x, y coords from both cameras\n",
    "    x1, y1 = data_1[frame_id, 1], data_1[frame_id, 2]\n",
    "    x2, y2 = data_2[int(j), 1], data_2[int(j), 2]\n",
    "\n",
    "    # undistort points using cv2 method\n",
    "    ray1 = cv2.undistortPoints(np.array([[[x1, y1]]], dtype=np.float32), K1, dist1, P=K1)\n",
    "    ray2 = cv2.undistortPoints(np.array([[[x2, y2]]], dtype=np.float32), K2, dist2, P=K2)\n",
    "\n",
    "    # transform rays to world coordinates\n",
    "    \n",
    "\n",
    "    # triangulate 3d point from rays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b174d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might be easier to run the detection on both videos and save to file, \n",
    "# then just get the frame id and the detection info directly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drone-detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
